{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA INSERTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in ZIP archive: ['test.csv', 'train.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_5304\\1031665088.py:14: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data = pd.read_csv(train_file)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_5304\\1031665088.py:17: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_data = pd.read_csv(test_file)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "# Define the ZIP file path\n",
    "zip_file_path = \"data_files.zip\"  # Replace with the path to your ZIP file\n",
    "\n",
    "# Open the ZIP file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # List all files in the ZIP archive (for debugging or verification)\n",
    "    print(\"Files in ZIP archive:\", zip_ref.namelist())\n",
    "    \n",
    "    # Open CSV files directly\n",
    "    with zip_ref.open(\"train.csv\") as train_file:\n",
    "        train_data = pd.read_csv(train_file)\n",
    "    \n",
    "    with zip_ref.open(\"test.csv\") as test_file:\n",
    "        test_data = pd.read_csv(test_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 107437 entries, 0 to 107436\n",
      "Data columns (total 55 columns):\n",
      " #   Column                                  Non-Null Count   Dtype  \n",
      "---  ------                                  --------------   -----  \n",
      " 0   Characteristics.LotFeatures             42020 non-null   object \n",
      " 1   Characteristics.LotSizeSquareFeet       1690 non-null    float64\n",
      " 2   ImageData.c1c6.summary.bathroom         90744 non-null   float64\n",
      " 3   ImageData.c1c6.summary.exterior         87789 non-null   float64\n",
      " 4   ImageData.c1c6.summary.interior         93597 non-null   float64\n",
      " 5   ImageData.c1c6.summary.kitchen          92320 non-null   float64\n",
      " 6   ImageData.c1c6.summary.property         103055 non-null  float64\n",
      " 7   ImageData.features_reso.results         104780 non-null  object \n",
      " 8   ImageData.q1q6.summary.bathroom         90708 non-null   float64\n",
      " 9   ImageData.q1q6.summary.exterior         82565 non-null   float64\n",
      " 10  ImageData.q1q6.summary.interior         93589 non-null   float64\n",
      " 11  ImageData.q1q6.summary.kitchen          92292 non-null   float64\n",
      " 12  ImageData.q1q6.summary.property         101798 non-null  float64\n",
      " 13  ImageData.room_type_reso.results        106874 non-null  object \n",
      " 14  ImageData.style.exterior.summary.label  83573 non-null   object \n",
      " 15  ImageData.style.stories.summary.label   83351 non-null   object \n",
      " 16  Listing.Dates.CloseDate                 107437 non-null  object \n",
      " 17  Listing.ListingId                       107437 non-null  object \n",
      " 18  Listing.Price.ClosePrice                107437 non-null  float64\n",
      " 19  Location.Address.CensusBlock            100440 non-null  object \n",
      " 20  Location.Address.CensusTract            100440 non-null  object \n",
      " 21  Location.Address.City                   107437 non-null  object \n",
      " 22  Location.Address.CountyOrParish         106824 non-null  object \n",
      " 23  Location.Address.PostalCode             107437 non-null  object \n",
      " 24  Location.Address.PostalCodePlus4        3271 non-null    object \n",
      " 25  Location.Address.StateOrProvince        107437 non-null  object \n",
      " 26  Location.Address.StreetDirectionPrefix  48694 non-null   object \n",
      " 27  Location.Address.StreetDirectionSuffix  641 non-null     object \n",
      " 28  Location.Address.StreetName             107433 non-null  object \n",
      " 29  Location.Address.StreetNumber           107412 non-null  object \n",
      " 30  Location.Address.StreetSuffix           106074 non-null  object \n",
      " 31  Location.Address.UnitNumber             24543 non-null   object \n",
      " 32  Location.Address.UnparsedAddress        107437 non-null  object \n",
      " 33  Location.Area.SubdivisionName           36541 non-null   object \n",
      " 34  Location.GIS.Latitude                   100440 non-null  float64\n",
      " 35  Location.GIS.Longitude                  100440 non-null  float64\n",
      " 36  Location.School.HighSchoolDistrict      105255 non-null  object \n",
      " 37  Property.PropertyType                   107437 non-null  object \n",
      " 38  Structure.Basement                      102828 non-null  object \n",
      " 39  Structure.BathroomsFull                 100063 non-null  float64\n",
      " 40  Structure.BathroomsHalf                 100049 non-null  float64\n",
      " 41  Structure.BedroomsTotal                 105024 non-null  float64\n",
      " 42  Structure.BelowGradeFinishedArea        14235 non-null   float64\n",
      " 43  Structure.BelowGradeUnfinishedArea      11674 non-null   float64\n",
      " 44  Structure.Cooling                       101487 non-null  object \n",
      " 45  Structure.FireplacesTotal               51216 non-null   float64\n",
      " 46  Structure.GarageSpaces                  88621 non-null   float64\n",
      " 47  Structure.Heating                       104987 non-null  object \n",
      " 48  Structure.LivingArea                    99509 non-null   float64\n",
      " 49  Structure.NewConstructionYN             106344 non-null  object \n",
      " 50  Structure.ParkingFeatures               13557 non-null   object \n",
      " 51  Structure.Rooms.RoomsTotal              105061 non-null  float64\n",
      " 52  Structure.YearBuilt                     102256 non-null  float64\n",
      " 53  Tax.Zoning                              7498 non-null    object \n",
      " 54  UnitTypes.UnitTypeType                  4976 non-null    object \n",
      "dtypes: float64(24), object(31)\n",
      "memory usage: 45.1+ MB\n",
      "None\n",
      "\n",
      "Test Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22039 entries, 0 to 22038\n",
      "Data columns (total 54 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   Characteristics.LotFeatures             8989 non-null   object \n",
      " 1   Characteristics.LotSizeSquareFeet       274 non-null    float64\n",
      " 2   ImageData.c1c6.summary.bathroom         19387 non-null  float64\n",
      " 3   ImageData.c1c6.summary.exterior         17476 non-null  float64\n",
      " 4   ImageData.c1c6.summary.interior         19804 non-null  float64\n",
      " 5   ImageData.c1c6.summary.kitchen          19644 non-null  float64\n",
      " 6   ImageData.c1c6.summary.property         21022 non-null  float64\n",
      " 7   ImageData.features_reso.results         21418 non-null  object \n",
      " 8   ImageData.q1q6.summary.bathroom         19385 non-null  float64\n",
      " 9   ImageData.q1q6.summary.exterior         16232 non-null  float64\n",
      " 10  ImageData.q1q6.summary.interior         19806 non-null  float64\n",
      " 11  ImageData.q1q6.summary.kitchen          19644 non-null  float64\n",
      " 12  ImageData.q1q6.summary.property         20871 non-null  float64\n",
      " 13  ImageData.room_type_reso.results        21804 non-null  object \n",
      " 14  ImageData.style.exterior.summary.label  16432 non-null  object \n",
      " 15  ImageData.style.stories.summary.label   16635 non-null  object \n",
      " 16  Listing.Dates.CloseDate                 22039 non-null  object \n",
      " 17  Listing.ListingId                       22039 non-null  object \n",
      " 18  Location.Address.CensusBlock            20917 non-null  object \n",
      " 19  Location.Address.CensusTract            20917 non-null  object \n",
      " 20  Location.Address.City                   22039 non-null  object \n",
      " 21  Location.Address.CountyOrParish         21940 non-null  object \n",
      " 22  Location.Address.PostalCode             22039 non-null  object \n",
      " 23  Location.Address.PostalCodePlus4        714 non-null    object \n",
      " 24  Location.Address.StateOrProvince        22039 non-null  object \n",
      " 25  Location.Address.StreetDirectionPrefix  9818 non-null   object \n",
      " 26  Location.Address.StreetDirectionSuffix  132 non-null    object \n",
      " 27  Location.Address.StreetName             22038 non-null  object \n",
      " 28  Location.Address.StreetNumber           22037 non-null  object \n",
      " 29  Location.Address.StreetSuffix           21795 non-null  object \n",
      " 30  Location.Address.UnitNumber             4983 non-null   object \n",
      " 31  Location.Address.UnparsedAddress        22039 non-null  object \n",
      " 32  Location.Area.SubdivisionName           7732 non-null   object \n",
      " 33  Location.GIS.Latitude                   20917 non-null  float64\n",
      " 34  Location.GIS.Longitude                  20917 non-null  float64\n",
      " 35  Location.School.HighSchoolDistrict      21628 non-null  object \n",
      " 36  Property.PropertyType                   22039 non-null  object \n",
      " 37  Structure.Basement                      21253 non-null  object \n",
      " 38  Structure.BathroomsFull                 20743 non-null  float64\n",
      " 39  Structure.BathroomsHalf                 20742 non-null  float64\n",
      " 40  Structure.BedroomsTotal                 21629 non-null  float64\n",
      " 41  Structure.BelowGradeFinishedArea        3100 non-null   float64\n",
      " 42  Structure.BelowGradeUnfinishedArea      2528 non-null   float64\n",
      " 43  Structure.Cooling                       20952 non-null  object \n",
      " 44  Structure.FireplacesTotal               11057 non-null  float64\n",
      " 45  Structure.GarageSpaces                  18453 non-null  float64\n",
      " 46  Structure.Heating                       21600 non-null  object \n",
      " 47  Structure.LivingArea                    20625 non-null  float64\n",
      " 48  Structure.NewConstructionYN             21651 non-null  object \n",
      " 49  Structure.ParkingFeatures               2750 non-null   object \n",
      " 50  Structure.Rooms.RoomsTotal              21608 non-null  float64\n",
      " 51  Structure.YearBuilt                     20954 non-null  float64\n",
      " 52  Tax.Zoning                              1357 non-null   object \n",
      " 53  UnitTypes.UnitTypeType                  895 non-null    object \n",
      "dtypes: float64(23), object(31)\n",
      "memory usage: 9.1+ MB\n",
      "None\n",
      "Size of the dataset: 107437\n"
     ]
    }
   ],
   "source": [
    "# Display basic information\n",
    "print(\"Train Data:\")\n",
    "print(train_data.info())\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_data.info())\n",
    "\n",
    "# Preview the first few rows of the train and test datasets\n",
    "n = len(train_data)\n",
    "print(f\"Size of the dataset: {n}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING AND PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DROPPING UNNECESSARY COLUMNS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "cleaned_train_data = train_data.copy()\n",
    "cleaned_train_data = cleaned_train_data.drop(columns=[\"Location.Address.CensusTract\", \"Location.School.HighSchoolDistrict\", 'Location.Address.PostalCodePlus4', 'Location.Address.UnparsedAddress', 'Location.Address.StreetDirectionPrefix','Location.Address.StreetDirectionSuffix','Location.Address.StreetNumber', 'Characteristics.LotFeatures', 'Listing.Dates.CloseDate', 'Location.Address.StateOrProvince', 'Location.GIS.Latitude', 'Location.GIS.Longitude', 'Location.Address.UnitNumber', 'Characteristics.LotSizeSquareFeet', 'Location.Area.SubdivisionName', 'Structure.BelowGradeFinishedArea', 'Structure.BelowGradeUnfinishedArea', 'Structure.ParkingFeatures', 'Tax.Zoning', 'UnitTypes.UnitTypeType', 'Location.Address.City', 'Location.Address.CountyOrParish', 'ImageData.style.exterior.summary.label', 'Location.Address.StreetName', 'Structure.Heating', 'Location.Address.StreetSuffix'])\n",
    "print(len(cleaned_train_data.columns))\n",
    "\n",
    "cleaned_test_data = test_data.copy()\n",
    "cleaned_test_data = cleaned_test_data.drop(columns=[\"Location.Address.CensusTract\", \"Location.School.HighSchoolDistrict\", 'Location.Address.PostalCodePlus4', 'Location.Address.UnparsedAddress', 'Location.Address.StreetDirectionPrefix','Location.Address.StreetDirectionSuffix','Location.Address.StreetNumber', 'Characteristics.LotFeatures', 'Listing.Dates.CloseDate', 'Location.Address.StateOrProvince', 'Location.GIS.Latitude', 'Location.GIS.Longitude', 'Location.Address.UnitNumber', 'Characteristics.LotSizeSquareFeet', 'Location.Area.SubdivisionName', 'Structure.BelowGradeFinishedArea', 'Structure.BelowGradeUnfinishedArea', 'Structure.ParkingFeatures', 'Tax.Zoning', 'UnitTypes.UnitTypeType', 'Location.Address.City', 'Location.Address.CountyOrParish', 'ImageData.style.exterior.summary.label', 'Location.Address.StreetName', 'Structure.Heating', 'Location.Address.StreetSuffix'])\n",
    "print(len(cleaned_test_data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DROPPING ROWS WITH FEW FEATURES DEFINED \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after removal: (107437, 29)\n",
      "Dataset shape after removal: (22039, 28)\n"
     ]
    }
   ],
   "source": [
    "# # Find rows with less than 10 non-null features\n",
    "# rows_with_few_features = cleaned_train_data[cleaned_train_data.notnull().sum(axis=1) < 20]\n",
    "# # Print rows with fewer than 10 non-null features (optional)\n",
    "# print(f\"Number of rows with fewer than 20 non-null features: {len(rows_with_few_features)}\")\n",
    "# # Remove these rows from the dataset\n",
    "# cleaned_train_data = cleaned_train_data[cleaned_train_data.notnull().sum(axis=1) >= 20]\n",
    "# # Verify the new dataset shape\n",
    "print(f\"Dataset shape after removal: {cleaned_train_data.shape}\")\n",
    "\n",
    "# # Find rows with less than 10 non-null features\n",
    "# rows_with_few_features = cleaned_test_data[cleaned_test_data.notnull().sum(axis=1) < 20]\n",
    "# # Print rows with fewer than 10 non-null features (optional)\n",
    "# print(f\"Number of rows with fewer than 20 non-null features: {len(rows_with_few_features)}\")\n",
    "# # Remove these rows from the dataset\n",
    "# cleaned_test_data = cleaned_test_data[cleaned_test_data.notnull().sum(axis=1) >= 20]\n",
    "# # Verify the new dataset shape\n",
    "print(f\"Dataset shape after removal: {cleaned_test_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVERTING CATEGORICAL FEATURES TO NUMERICAL AND HANDLING NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We convert this numerical featuer first because we will need values of a categoricak features, otherwise we'd loose that information\n",
    "# Convert `Structure.FireplacesTotal` to binary (1 if >0, 0 if 0 or NaN)\n",
    "cleaned_train_data[\"Structure.FireplacesTotal\"] = cleaned_train_data[\"Structure.FireplacesTotal\"].apply(lambda x: 1 if pd.notnull(x) and x > 0 else 0)\n",
    "# Identify houses with \"fireplace\" in `ImageData.features_reso.results`\n",
    "def has_fireplace(features):\n",
    "    if isinstance(features, list):  # Ensure it's a list\n",
    "        return any(\"fireplace\" in feature.lower() for feature in features)\n",
    "    return False\n",
    "cleaned_train_data[\"HasFireplaceFromImage\"] = cleaned_train_data[\"ImageData.features_reso.results\"].apply(has_fireplace)\n",
    "# Update `Structure.FireplacesTotal` based on `HasFireplaceFromImage`\n",
    "cleaned_train_data[\"Structure.FireplacesTotal\"] = cleaned_train_data.apply(\n",
    "    lambda row: 1 if row[\"HasFireplaceFromImage\"] and row[\"Structure.FireplacesTotal\"] == 0 else row[\"Structure.FireplacesTotal\"],\n",
    "    axis=1\n",
    ")\n",
    "# Drop the temporary column \n",
    "cleaned_train_data.drop(columns=[\"HasFireplaceFromImage\"], inplace=True)\n",
    "\n",
    "# We convert this numerical featuer first because we will need values of a categoricak features, otherwise we'd loose that information\n",
    "# Convert `Structure.FireplacesTotal` to binary (1 if >0, 0 if 0 or NaN)\n",
    "cleaned_test_data[\"Structure.FireplacesTotal\"] = cleaned_test_data[\"Structure.FireplacesTotal\"].apply(lambda x: 1 if pd.notnull(x) and x > 0 else 0)\n",
    "# Identify houses with \"fireplace\" in `ImageData.features_reso.results`\n",
    "def has_fireplace(features):\n",
    "    if isinstance(features, list):  # Ensure it's a list\n",
    "        return any(\"fireplace\" in feature.lower() for feature in features)\n",
    "    return False\n",
    "cleaned_test_data[\"HasFireplaceFromImage\"] = cleaned_test_data[\"ImageData.features_reso.results\"].apply(has_fireplace)\n",
    "# Update `Structure.FireplacesTotal` based on `HasFireplaceFromImage`\n",
    "cleaned_test_data[\"Structure.FireplacesTotal\"] = cleaned_test_data.apply(\n",
    "    lambda row: 1 if row[\"HasFireplaceFromImage\"] and row[\"Structure.FireplacesTotal\"] == 0 else row[\"Structure.FireplacesTotal\"],\n",
    "    axis=1\n",
    ")\n",
    "# Drop the temporary column \n",
    "cleaned_test_data.drop(columns=[\"HasFireplaceFromImage\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Convert string representations of lists to actual lists\n",
    "cleaned_train_data['ImageData.features_reso.results'] = cleaned_train_data['ImageData.features_reso.results'].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "# Fill missing values with empty lists\n",
    "cleaned_train_data['ImageData.features_reso.results'] = cleaned_train_data['ImageData.features_reso.results'].apply(\n",
    "    lambda x: x if isinstance(x, list) else []\n",
    ")\n",
    "# Modify the column to contain the count of features\n",
    "cleaned_train_data['ImageData.features_reso.results'] = cleaned_train_data['ImageData.features_reso.results'].apply(len)\n",
    "\n",
    "\n",
    "# Convert string representations of lists to actual lists\n",
    "cleaned_test_data['ImageData.features_reso.results'] = cleaned_test_data['ImageData.features_reso.results'].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "# Fill missing values with empty lists\n",
    "cleaned_test_data['ImageData.features_reso.results'] = cleaned_test_data['ImageData.features_reso.results'].apply(\n",
    "    lambda x: x if isinstance(x, list) else []\n",
    ")\n",
    "# Modify the column to contain the count of features\n",
    "cleaned_test_data['ImageData.features_reso.results'] = cleaned_test_data['ImageData.features_reso.results'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to process\n",
    "columns_to_process = [\n",
    "    'ImageData.c1c6.summary.bathroom',\n",
    "    'ImageData.c1c6.summary.exterior',\n",
    "    'ImageData.c1c6.summary.interior',\n",
    "    'ImageData.c1c6.summary.kitchen',\n",
    "    'ImageData.c1c6.summary.property',\n",
    "    'ImageData.q1q6.summary.bathroom', \n",
    "    'ImageData.q1q6.summary.exterior',\n",
    "    'ImageData.q1q6.summary.interior', \n",
    "    'ImageData.q1q6.summary.kitchen',\n",
    "    'ImageData.q1q6.summary.property'\n",
    "    \n",
    "]\n",
    "\n",
    "# Impute missing values with the median\n",
    "for col in columns_to_process:    \n",
    "    median_value = cleaned_train_data[col].median()\n",
    "    cleaned_train_data[col] = cleaned_train_data[col].fillna(median_value)\n",
    "\n",
    "\n",
    "# Impute missing values with the median\n",
    "for col in columns_to_process:    \n",
    "    cleaned_test_data[col] = cleaned_test_data[col].fillna(median_value) #we use train data for median computation for more accurate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for train data\n",
    "cleaned_train_data['ImageData.room_type_reso.results'] = cleaned_train_data['ImageData.room_type_reso.results'].apply(\n",
    "    lambda x: len(ast.literal_eval(x)) if isinstance(x, str) else (len(x) if isinstance(x, list) else 0)\n",
    ")\n",
    "\n",
    "# Fix for test data\n",
    "cleaned_test_data['ImageData.room_type_reso.results'] = cleaned_test_data['ImageData.room_type_reso.results'].apply(\n",
    "    lambda x: len(ast.literal_eval(x)) if isinstance(x, str) else (len(x) if isinstance(x, list) else 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_5304\\1341542865.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_train_data['Structure.GarageSpaces'].fillna(global_median, inplace=True)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_5304\\1341542865.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_test_data['Structure.GarageSpaces'].fillna(global_median, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values within groups by the median of the respective group\n",
    "cleaned_train_data['Structure.GarageSpaces'] = cleaned_train_data.groupby('Property.PropertyType')['Structure.GarageSpaces'].transform(lambda x: x.fillna(x.median()))\n",
    "# Fill any remaining NaN values with the global median (if any group had no data to compute the median)\n",
    "global_median = cleaned_train_data['Structure.GarageSpaces'].median()\n",
    "cleaned_train_data['Structure.GarageSpaces'].fillna(global_median, inplace=True)\n",
    "\n",
    "\n",
    "# Fill missing values within groups by the median of the respective group\n",
    "cleaned_test_data['Structure.GarageSpaces'] = cleaned_test_data.groupby('Property.PropertyType')['Structure.GarageSpaces'].transform(lambda x: x.fillna(x.median()))\n",
    "# Fill any remaining NaN values with the global median (if any group had no data to compute the median)\n",
    "cleaned_test_data['Structure.GarageSpaces'].fillna(global_median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_data = cleaned_train_data.drop(columns='Property.PropertyType')\n",
    "cleaned_test_data = cleaned_test_data.drop(columns='Property.PropertyType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply One-Hot Encoding to 'Property.PropertyType'\n",
    "# encoded_property_type = pd.get_dummies(cleaned_train_data['Property.PropertyType'], prefix='Property_Type')\n",
    "# # Concatenate the encoded columns with the original DataFrame\n",
    "# cleaned_train_data = pd.concat([cleaned_train_data, encoded_property_type], axis=1)\n",
    "# cleaned_train_data = cleaned_train_data.drop(columns=[\"Property.PropertyType\"])\n",
    "\n",
    "# # Apply One-Hot Encoding to 'Property.PropertyType'\n",
    "# encoded_property_type = pd.get_dummies(cleaned_test_data['Property.PropertyType'], prefix='Property_Type')\n",
    "# # Concatenate the encoded columns with the original DataFrame\n",
    "# cleaned_test_data = pd.concat([cleaned_test_data, encoded_property_type], axis=1)\n",
    "# cleaned_test_data = cleaned_test_data.drop(columns=[\"Property.PropertyType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_basement(row):\n",
    "    if pd.notnull(row['Structure.Basement']):\n",
    "        if 'none' in row['Structure.Basement']:\n",
    "            return 0\n",
    "        return 1\n",
    "    else:\n",
    "        # Check if 'ImageData.room_type_reso.results' is not null and is a list\n",
    "        if pd.notnull(row['ImageData.room_type_reso.results']) and isinstance(row['ImageData.room_type_reso.results'], list):           \n",
    "            if 'basement' in row['ImageData.room_type_reso.results']:\n",
    "                return 1\n",
    "    # If no basement found in both columns, return 0\n",
    "    return 0\n",
    "cleaned_train_data['Structure.Basement'] = cleaned_train_data.apply(transform_basement, axis=1)\n",
    "\n",
    "cleaned_test_data['Structure.Basement'] = cleaned_test_data.apply(transform_basement, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_5304\\2795932034.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_train_data['Structure.BathroomsFull'].fillna(median_full, inplace=True)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_5304\\2795932034.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_train_data['Structure.BathroomsHalf'].fillna(median_half, inplace=True)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_5304\\2795932034.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_test_data['Structure.BathroomsFull'].fillna(median_full, inplace=True)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_5304\\2795932034.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_test_data['Structure.BathroomsHalf'].fillna(median_half, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values: Impute with median\n",
    "median_full = cleaned_train_data['Structure.BathroomsFull'].median()\n",
    "cleaned_train_data['Structure.BathroomsFull'].fillna(median_full, inplace=True)\n",
    "median_half = cleaned_train_data['Structure.BathroomsHalf'].median()\n",
    "cleaned_train_data['Structure.BathroomsHalf'].fillna(median_half, inplace=True)\n",
    "# Create TotalBathrooms feature\n",
    "cleaned_train_data['TotalBathrooms'] = (\n",
    "    cleaned_train_data['Structure.BathroomsFull'] +\n",
    "    0.5 * cleaned_train_data['Structure.BathroomsHalf']\n",
    ")\n",
    "# Drop original columns\n",
    "cleaned_train_data.drop(columns=['Structure.BathroomsFull', 'Structure.BathroomsHalf'], inplace=True)\n",
    "\n",
    "# Handle missing values: Impute with median\n",
    "cleaned_test_data['Structure.BathroomsFull'].fillna(median_full, inplace=True)\n",
    "cleaned_test_data['Structure.BathroomsHalf'].fillna(median_half, inplace=True)\n",
    "# Create TotalBathrooms feature\n",
    "cleaned_test_data['TotalBathrooms'] = (\n",
    "    cleaned_test_data['Structure.BathroomsFull'] +\n",
    "    0.5 * cleaned_test_data['Structure.BathroomsHalf']\n",
    ")\n",
    "# Drop original columns\n",
    "cleaned_test_data.drop(columns=['Structure.BathroomsFull', 'Structure.BathroomsHalf'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_5304\\1799808172.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_train_data['Structure.BedroomsTotal'].fillna(median_bedrooms, inplace=True)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_5304\\1799808172.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_test_data['Structure.BedroomsTotal'].fillna(median_bedrooms, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values: Impute with median\n",
    "median_bedrooms = cleaned_train_data['Structure.BedroomsTotal'].median()\n",
    "cleaned_train_data['Structure.BedroomsTotal'].fillna(median_bedrooms, inplace=True)\n",
    "\n",
    "# Handle missing values: Impute with median\n",
    "cleaned_test_data['Structure.BedroomsTotal'].fillna(median_bedrooms, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_cooling(row):\n",
    "    if pd.notnull(row['Structure.Cooling']):\n",
    "        if 'none' in row['Structure.Cooling']:\n",
    "            return 0\n",
    "        return 1\n",
    "    else:\n",
    "        if pd.notnull(row['ImageData.features_reso.results']) and isinstance(row['ImageData.features_reso.results'], list):           \n",
    "            if 'cooling' in row['ImageData.features_reso.results']:\n",
    "                return 1\n",
    "    # If no basement found in both columns, return 0\n",
    "    return 0\n",
    "cleaned_train_data['Structure.Cooling'] = cleaned_train_data.apply(transform_cooling, axis=1)\n",
    "\n",
    "cleaned_test_data['Structure.Cooling'] = cleaned_test_data.apply(transform_cooling, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_5304\\2073616298.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_train_data['Structure.LivingArea'].fillna(mean_living_area, inplace=True)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_5304\\2073616298.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_test_data['Structure.LivingArea'].fillna(mean_living_area, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "mean_living_area = cleaned_train_data['Structure.LivingArea'].mean()\n",
    "cleaned_train_data['Structure.LivingArea'].fillna(mean_living_area, inplace=True)\n",
    "\n",
    "cleaned_test_data['Structure.LivingArea'].fillna(mean_living_area, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to impute missing values in 'Structure.NewConstructionYN' based on the year of construction\n",
    "def impute_new_construction(row):\n",
    "    if pd.isnull(row['Structure.NewConstructionYN']):\n",
    "        # Impute based on 'Structure.YearBuilt'\n",
    "        if row['Structure.YearBuilt'] > 2020:\n",
    "            return True\n",
    "        else:\n",
    "            return False \n",
    "    return row['Structure.NewConstructionYN']  # If not null, return the existing value\n",
    "\n",
    "# Apply the function to impute missing values\n",
    "cleaned_train_data['Structure.NewConstructionYN'] = cleaned_train_data.apply(impute_new_construction, axis=1)\n",
    "\n",
    "cleaned_test_data['Structure.NewConstructionYN'] = cleaned_test_data.apply(impute_new_construction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_5304\\4033238223.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_train_data['Structure.YearBuilt'].fillna(median_year, inplace=True)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_5304\\4033238223.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_test_data['Structure.YearBuilt'].fillna(median_year, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "median_year = cleaned_train_data['Structure.YearBuilt'].median()\n",
    "cleaned_train_data['Structure.YearBuilt'].fillna(median_year, inplace=True)\n",
    "current_year = 2024\n",
    "cleaned_train_data['PropertyAge'] = current_year - cleaned_train_data['Structure.YearBuilt']\n",
    "cleaned_train_data = cleaned_train_data.drop(columns=['Structure.YearBuilt'])\n",
    "\n",
    "cleaned_test_data['Structure.YearBuilt'].fillna(median_year, inplace=True)\n",
    "current_year = 2024\n",
    "cleaned_test_data['PropertyAge'] = current_year - cleaned_test_data['Structure.YearBuilt']\n",
    "cleaned_test_data = cleaned_test_data.drop(columns=['Structure.YearBuilt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping function to convert story labels to numeric values\n",
    "def map_stories_to_numeric(value):\n",
    "    if pd.isnull(value):\n",
    "        return value  # Keep the NaN value\n",
    "    elif value == '1_story':\n",
    "        return 1\n",
    "    elif value == '2_stories':\n",
    "        return 2\n",
    "    elif value == '3_stories_or_more':\n",
    "        return 3\n",
    "    elif value == '1.5_stories':\n",
    "        return 1.5\n",
    "    elif value == '2.5_stories':\n",
    "        return 2.5\n",
    "\n",
    "cleaned_train_data['ImageData.style.stories.summary.label'] = cleaned_train_data['ImageData.style.stories.summary.label'].apply(map_stories_to_numeric)\n",
    "# Fill null values with the median of the column\n",
    "median_value = cleaned_train_data['ImageData.style.stories.summary.label'].median()\n",
    "cleaned_train_data['ImageData.style.stories.summary.label'] = cleaned_train_data['ImageData.style.stories.summary.label'].fillna(median_value)\n",
    "\n",
    "\n",
    "cleaned_test_data['ImageData.style.stories.summary.label'] = cleaned_test_data['ImageData.style.stories.summary.label'].apply(map_stories_to_numeric)\n",
    "# Fill null values with the median of the column\n",
    "cleaned_test_data['ImageData.style.stories.summary.label'] = cleaned_test_data['ImageData.style.stories.summary.label'].fillna(median_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_data['Structure.Rooms.RoomsTotal'] = cleaned_train_data['Structure.Rooms.RoomsTotal'].fillna(\n",
    "    cleaned_train_data['Structure.BedroomsTotal'] + \n",
    "    cleaned_train_data['TotalBathrooms'] + \n",
    "    2  # Add 1 for common areas (e.g., kitchen, living room)\n",
    ")\n",
    "\n",
    "cleaned_test_data['Structure.Rooms.RoomsTotal'] = cleaned_test_data['Structure.Rooms.RoomsTotal'].fillna(\n",
    "    cleaned_train_data['Structure.BedroomsTotal'] + \n",
    "    cleaned_train_data['TotalBathrooms'] + \n",
    "    2  # Add 1 for common areas (e.g., kitchen, living room)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Step 1: Calculate mean prices by postal code\n",
    "# postal_code_mean_price = cleaned_train_data.groupby('Location.Address.PostalCode')['Listing.Price.ClosePrice'].mean()\n",
    "\n",
    "# # Step 2: Normalize the mean prices to a range of 0 to 1\n",
    "# scaler = MinMaxScaler()\n",
    "# postal_code_normalized = scaler.fit_transform(postal_code_mean_price.values.reshape(-1, 1))\n",
    "\n",
    "# # Step 3: Map the normalized scores back to the postal codes\n",
    "# postal_code_score = pd.DataFrame({\n",
    "#     'Location.Address.PostalCode': postal_code_mean_price.index,\n",
    "#     'PostalCode_Score': postal_code_normalized.flatten()\n",
    "# })\n",
    "\n",
    "# # Step 4: Merge the scores back into the original DataFrame\n",
    "# cleaned_train_data = cleaned_train_data.merge(postal_code_score, on='Location.Address.PostalCode', how='left')\n",
    "# cleaned_train_data = cleaned_train_data.drop(columns=['Location.Address.PostalCode'])\n",
    "\n",
    "\n",
    "# # Step 4: Merge the scores back into the original DataFrame\n",
    "# cleaned_test_data = cleaned_test_data.merge(postal_code_score, on='Location.Address.PostalCode', how='left')\n",
    "# cleaned_test_data = cleaned_test_data.drop(columns=['Location.Address.PostalCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_5304\\4270457193.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_train_data['Income'].fillna(mean_income, inplace=True)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_5304\\4270457193.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_test_data['Income'].fillna(mean_income, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Step 1: Load the Excel file\n",
    "zip_income_data = pd.read_excel('Filtered_ZIP_Codes_Total_Income.xlsx')  # Replace with your file path\n",
    "\n",
    "# Step 2: Create a mapping dictionary\n",
    "zip_to_income = dict(zip(zip_income_data['ZIP_CODE'], zip_income_data['total_income']))\n",
    "# Step 3: Map the incomes to the PostalCode column in your DataFrame\n",
    "cleaned_train_data['Income'] = cleaned_train_data['Location.Address.PostalCode'].map(zip_to_income)\n",
    "# Step 4: Handle missing ZIP codes\n",
    "# Replace NaN with the mean or median income of the Excel data\n",
    "mean_income = zip_income_data['total_income'].mean()\n",
    "cleaned_train_data['Income'].fillna(mean_income, inplace=True)\n",
    "# Step 5: Normalize the income column to a score (0-1)\n",
    "scaler = MinMaxScaler()\n",
    "cleaned_train_data['Income'] = scaler.fit_transform(cleaned_train_data[['Income']])\n",
    "cleaned_train_data = cleaned_train_data.drop(columns=[\"Location.Address.PostalCode\"])\n",
    "\n",
    "# Step 3: Map the incomes to the PostalCode column in your DataFrame\n",
    "cleaned_test_data['Income'] = cleaned_test_data['Location.Address.PostalCode'].map(zip_to_income)\n",
    "# Step 4: Handle missing ZIP codes\n",
    "# Replace NaN with the mean or median income of the Excel data\n",
    "cleaned_test_data['Income'].fillna(mean_income, inplace=True)\n",
    "cleaned_test_data['Income'] = scaler.fit_transform(cleaned_test_data[['Income']])\n",
    "cleaned_test_data = cleaned_test_data.drop(columns=[\"Location.Address.PostalCode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Calculate mean prices by postal code\n",
    "census_block_mean_price = cleaned_train_data.groupby('Location.Address.CensusBlock')['Listing.Price.ClosePrice'].mean()\n",
    "\n",
    "# Step 2: Normalize the mean prices to a range of 0 to 1\n",
    "scaler = MinMaxScaler()\n",
    "census_block_normalized = scaler.fit_transform(census_block_mean_price.values.reshape(-1, 1))\n",
    "\n",
    "# Step 3: Map the normalized scores back to the postal codes\n",
    "census_block_score = pd.DataFrame({\n",
    "    'Location.Address.CensusBlock': census_block_mean_price.index,\n",
    "    'CensusBlock_Score': census_block_normalized.flatten()\n",
    "})\n",
    "\n",
    "# Step 4: Merge the scores back into the original DataFrame\n",
    "cleaned_train_data = cleaned_train_data.merge(census_block_score, on='Location.Address.CensusBlock', how='left')\n",
    "cleaned_train_data = cleaned_train_data.drop(columns=['Location.Address.CensusBlock'])\n",
    "\n",
    "\n",
    "cleaned_test_data = cleaned_test_data.merge(census_block_score, on='Location.Address.CensusBlock', how='left')\n",
    "cleaned_test_data = cleaned_test_data.drop(columns=['Location.Address.CensusBlock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = ['Structure.NewConstructionYN']\n",
    "\n",
    "# Convert True/False to 1/0\n",
    "cleaned_train_data[columns_to_convert] = cleaned_train_data[columns_to_convert].astype(int)\n",
    "\n",
    "cleaned_test_data[columns_to_convert] = cleaned_test_data[columns_to_convert].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_data.to_csv('cleaned_train_data.csv', index=False)\n",
    "cleaned_test_data.to_csv('cleaned_test_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
